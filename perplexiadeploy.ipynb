{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccda43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from groq import Groq\n",
    "\n",
    "# 1. Initialize the Groq Client\n",
    "# The client automatically looks for the GROQ_API_KEY environment variable.\n",
    "client = Groq(api key )\n",
    "\n",
    "# 2. Define the Model (The fast, high-limit Llama)\n",
    "MODEL_NAME = \"llama-3.1-8b-instant\"\n",
    "\n",
    "# 3. Define the complex, structured request (forcing 5 industrial projects into JSON)\n",
    "JSON_EXTRACTION_PROMPT = \"\"\"\n",
    "I require the output ONLY in JSON format, adhering to the structure defined below.\n",
    "The primary object should be named 'projects', containing an array of 5 objects.\n",
    "Each object must contain the following six keys: 'ProjectName', 'ProjectSize (sqm)',\n",
    "'Contractor', 'OwnerDeveloper', 'Status', and 'EstimatedCompletion'.\n",
    "Find the top 5 largest upcoming industrial projects in Egypt and fill in the data for each of those keys.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": JSON_EXTRACTION_PROMPT,\n",
    "    }\n",
    "]\n",
    "\n",
    "# 4. Send the request with structured output enforcement\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=MODEL_NAME,\n",
    "    # This feature tells the Groq Llama model to output valid JSON only\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    temperature=0.0, # Low temperature for accurate data extraction\n",
    ")\n",
    "\n",
    "# 5. Parse and print the resulting JSON object\n",
    "json_response = chat_completion.choices[0].message.content\n",
    "print(json_response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
